# Denoising Convolutional Autoencoder (DCAE)

This model uses a CNN Autoencoder to denoise speech spectrograms.
It can remove stationary and non-stationary noise, and can isolate main speakers from competing speakers. 

Text-to-speech (TTS) systems require substantial amounts of high-quality training data to produce natural-sounding synthetic voices, yet such data is expensive to record.
While open-source datasets offer an alternative, they often come with issues like background noise, reverberation, clipping, and limited bandwidth. Manually enhancing these datasets to studio quality can be equally costly.
Automatic speech restoration has emerged as a solution, but state-of-the-art models are complex and demand extensive training data, making them inaccessible to smaller teams relying on open-source data.



